{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696a39a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding batches: 100%|██████████| 8/8 [01:18<00:00,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 完成：總共處理 1300 筆課程，結果已儲存於 persist/chroma_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "import tiktoken\n",
    "from pydantic import SecretStr\n",
    "from chromadb.config import Settings\n",
    "\n",
    "RateLimitError = Exception\n",
    "\n",
    "# ====== CONFIG ======\n",
    "SOURCE_JSON = \"parsed_course_data.json\"\n",
    "CHROMA_DIR = \"persist/chroma_data\"\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "MAX_TOKENS_PER_BATCH = 250000\n",
    "BATCH_DELAY_SECONDS = 1.5\n",
    "# =====================\n",
    "\n",
    "# ✅ 初始化\n",
    "# 方法 1：使用 SecretStr 轉換\n",
    "embedding_model = OpenAIEmbeddings(api_key=SecretStr(OPENAI_API_KEY))\n",
    "# 或者方法 2：使用環境變數（無需額外設置）\n",
    "# embedding_model = OpenAIEmbeddings()\n",
    "tokenizer = tiktoken.encoding_for_model(EMBEDDING_MODEL_NAME)\n",
    "\n",
    "# ✅ 載入課程資料\n",
    "with open(SOURCE_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_courses = json.load(f)\n",
    "\n",
    "\n",
    "# ✅ 時間欄位轉 metadata（含字串與布林標記）\n",
    "def build_time_metadata(time_slots):\n",
    "    if isinstance(time_slots, list):\n",
    "        time_str = \",\".join(time_slots)\n",
    "        time_flags = {f\"ts_{ts}\": True for ts in time_slots}\n",
    "    else:\n",
    "        time_str = \"\"\n",
    "        time_flags = {}\n",
    "    return {\"time_slots\": time_str, **time_flags}\n",
    "\n",
    "\n",
    "# ✅ 建立 Document 列表\n",
    "documents = []\n",
    "for c in raw_courses:\n",
    "    content = f\"課程名稱：{c['title']}\\n課程介紹：{c['description']}\\n授課老師：{c.get('instructor','')}\\n課程網址：{c.get('course_url','')}\"\n",
    "    metadata = {\"course_id\": c[\"course_id\"], \"title\": c[\"title\"], \"instructor\": c.get(\"instructor\", \"\"), \"course_url\": c.get(\"course_url\", \"\"), **build_time_metadata(c.get(\"time_slots\", []))}\n",
    "    documents.append(Document(page_content=content, metadata=metadata))\n",
    "\n",
    "\n",
    "# ✅ 計算 token 數\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "\n",
    "# ✅ 按 token 數分批\n",
    "def batch_by_token_limit(docs: List[Document], max_tokens: int):\n",
    "    batch, total = [], 0\n",
    "    for doc in docs:\n",
    "        tokens = count_tokens(doc.page_content)\n",
    "        if total + tokens > max_tokens and batch:\n",
    "            yield batch\n",
    "            batch, total = [], 0\n",
    "        batch.append(doc)\n",
    "        total += tokens\n",
    "    if batch:\n",
    "        yield batch\n",
    "\n",
    "\n",
    "# ✅ 安全封裝的 add_texts，內建 retry\n",
    "@retry(wait=wait_random_exponential(min=2, max=10), stop=stop_after_attempt(5))\n",
    "def safe_add_texts(vectordb, texts, metadatas):\n",
    "    vectordb.add_texts(texts=texts, metadatas=metadatas)\n",
    "\n",
    "\n",
    "# ✅ 初始化 Chroma 向量庫，設置 persist_directory\n",
    "vectordb = Chroma(persist_directory=CHROMA_DIR, embedding_function=embedding_model, client_settings=Settings(is_persistent=True))\n",
    "\n",
    "# ✅ 分批嵌入與寫入\n",
    "batches = list(batch_by_token_limit(documents, MAX_TOKENS_PER_BATCH))\n",
    "for i, batch in enumerate(tqdm(batches, desc=\"Embedding batches\")):\n",
    "    texts = [d.page_content for d in batch]\n",
    "    metadatas = [d.metadata for d in batch]\n",
    "    safe_add_texts(vectordb, texts, metadatas)\n",
    "    time.sleep(BATCH_DELAY_SECONDS)\n",
    "\n",
    "# 資料會自動儲存，不需要呼叫 persist()\n",
    "print(f\"✅ 完成：總共處理 {len(documents)} 筆課程，結果已儲存於 {CHROMA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd074a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已壓縮為 chroma_data.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "\n",
    "def zip_chroma_data(folder_path, output_zip=\"chroma_data.zip\"):\n",
    "    with zipfile.ZipFile(output_zip, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                filepath = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(filepath, start=folder_path)\n",
    "                zipf.write(filepath, arcname)\n",
    "\n",
    "\n",
    "zip_chroma_data(\"persist/chroma_data\")  # ⬅ 這裡改成你的 Chroma 資料夾路徑\n",
    "print(\"✅ 已壓縮為 chroma_data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3dc8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 成功連線，列出 container 中的 blob:\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "account_name = os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\")\n",
    "account_key = os.getenv(\"AZURE_STORAGE_ACCOUNT_KEY\")\n",
    "container_name = os.getenv(\"AZURE_BLOB_CONTAINER\")\n",
    "\n",
    "connection_str = f\"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_str)\n",
    "\n",
    "try:\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    print(\"✅ 成功連線，列出 container 中的 blob:\")\n",
    "    for blob in container_client.list_blobs():\n",
    "        print(\" -\", blob.name)\n",
    "except Exception as e:\n",
    "    print(\"❌ 連線失敗，請檢查 account name/key/container name\")\n",
    "    print(\"錯誤訊息：\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6034fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 測試檔案已上傳\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobClient\n",
    "from azure.storage.blob import ContentSettings\n",
    "\n",
    "test_blob_name = \"test-upload.txt\"\n",
    "test_blob_client = blob_service_client.get_blob_client(container=container_name, blob=test_blob_name)\n",
    "\n",
    "with open(\"test-upload.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"這是一個測試檔案\")\n",
    "\n",
    "with open(\"test-upload.txt\", \"rb\") as data:\n",
    "    test_blob_client.upload_blob(data, overwrite=True, content_settings=ContentSettings(content_type=\"text/plain\"))\n",
    "    print(\"✅ 測試檔案已上傳\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35f2e161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📤 Uploading: 100%|██████████| 23.8M/23.8M [01:31<00:00, 261kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 上傳完成：course_vector.zip 至 container course-data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.storage.blob import BlobClient, ContentSettings\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --------------- 🔧 設定常數 ----------------\n",
    "LOCAL_FILE = \"chroma_data.zip\"\n",
    "BLOB_NAME = \"course_vector.zip\"\n",
    "CONTENT_TYPE = \"application/zip\"\n",
    "MAX_SINGLE_PUT_SIZE = 16 * 1024 * 1024  # 16MB\n",
    "MAX_BLOCK_SIZE = 4 * 1024 * 1024  # 4MB\n",
    "TIMEOUT = 600\n",
    "MAX_CONCURRENCY = 4\n",
    "\n",
    "# --------------- 🔐 載入憑證 ----------------\n",
    "load_dotenv()\n",
    "ACCOUNT_NAME = os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\")\n",
    "ACCOUNT_KEY = os.getenv(\"AZURE_STORAGE_ACCOUNT_KEY\")\n",
    "CONTAINER_NAME = os.getenv(\"AZURE_BLOB_CONTAINER\")\n",
    "\n",
    "if not all([ACCOUNT_NAME, ACCOUNT_KEY, CONTAINER_NAME]):\n",
    "    raise ValueError(\"❌ 請確認 .env 中帳號資訊是否齊全\")\n",
    "\n",
    "# --------------- 🔗 建立連線字串 ----------------\n",
    "AZURE_CONN_STR = f\"DefaultEndpointsProtocol=https;AccountName={ACCOUNT_NAME};AccountKey={ACCOUNT_KEY};EndpointSuffix=core.windows.net\"\n",
    "\n",
    "\n",
    "# --------------- 📦 準備上傳檔案 ----------------\n",
    "class TqdmUploadWrapper:\n",
    "    def __init__(self, file, total):\n",
    "        self.file = file\n",
    "        self.progress_bar = tqdm(total=total, unit=\"B\", unit_scale=True, desc=\"📤 Uploading\")\n",
    "\n",
    "    def read(self, size):\n",
    "        data = self.file.read(size)\n",
    "        self.progress_bar.update(len(data))\n",
    "        return data\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            chunk = self.read(1024 * 1024)  # Read in 1MB chunks\n",
    "            if not chunk:\n",
    "                break\n",
    "            yield chunk\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        return getattr(self.file, attr)\n",
    "\n",
    "\n",
    "# --------------- ☁️ 建立 BlobClient 並上傳 ----------------\n",
    "file_size = os.path.getsize(LOCAL_FILE)\n",
    "\n",
    "blob_client = BlobClient.from_connection_string(conn_str=AZURE_CONN_STR, container_name=CONTAINER_NAME, blob_name=BLOB_NAME, max_single_put_size=MAX_SINGLE_PUT_SIZE, max_block_size=MAX_BLOCK_SIZE)\n",
    "\n",
    "with open(LOCAL_FILE, \"rb\") as f:\n",
    "    wrapped = TqdmUploadWrapper(f, total=file_size)\n",
    "    blob_client.upload_blob(data=wrapped, blob_type=\"BlockBlob\", overwrite=True, content_settings=ContentSettings(content_type=CONTENT_TYPE), max_concurrency=MAX_CONCURRENCY, timeout=TIMEOUT)\n",
    "    wrapped.progress_bar.close()\n",
    "\n",
    "print(f\"\\n✅ 上傳完成：{BLOB_NAME} 至 container {CONTAINER_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93cd0c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 CHROMA_LOCAL_DIR 內容：\n",
      "chroma_data/\n",
      "  └─ chroma.sqlite3\n",
      "  8f32e79c-8252-4231-8783-bf4c51b313b8/\n",
      "    └─ data_level0.bin\n",
      "    └─ header.bin\n",
      "    └─ index_metadata.pickle\n",
      "    └─ length.bin\n",
      "    └─ link_lists.bin\n",
      "\n",
      "✅ 總共在 Chroma 找到 1300 筆文件\n",
      "  1. metadata: {'time_slots': '1_3,1_4', 'title': '(大)法官如何思考？司法行為與司法政治上', 'ts_1_3': True, 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=341%20U9340&class=&dpt_code=3410&ser_no=43630&semester=113-1&lang=CH', 'ts_1_4': True, 'course_id': 43630, 'instructor': '林建志'}\n",
      "  2. metadata: {'ts_1_8': True, 'time_slots': '1_8,1_9,5_1702', 'course_id': 62222, 'instructor': '黃銘傑', 'ts_5_1702': True, 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=A21%20M2490&class=&dpt_code=A410&ser_no=62222&semester=113-1&lang=CH', 'ts_1_9': True, 'title': '人工智慧、大數據與競爭法一'}\n",
      "  3. metadata: {'title': '人口統計學', 'course_id': 71504, 'instructor': '蘇士詠', 'time_slots': '3_6,3_7,3_8', 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=H41%20U0040&class=&dpt_code=H410&ser_no=71504&semester=113-1&lang=CH', 'ts_3_6': True, 'ts_3_7': True, 'ts_3_8': True}\n",
      "  4. metadata: {'course_id': 67518, 'time_slots': '', 'instructor': '溫在弘', 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=P46%20U0070&class=&dpt_code=P460&ser_no=67518&semester=113-1&lang=CH', 'title': '人口資料視覺化實作'}\n",
      "  5. metadata: {'title': '財務報表分析', 'course_id': 61032, 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=A21%20U6620&class=&dpt_code=A010&ser_no=61032&semester=113-1&lang=CH', 'time_slots': '1_8,1_9', 'instructor': '黃承祖', 'ts_1_9': True, 'ts_1_8': True}\n",
      "\n",
      "✅ 總共在 Chroma 找到 1300 筆文件\n",
      "  1. metadata: {'time_slots': '1_3,1_4', 'title': '(大)法官如何思考？司法行為與司法政治上', 'ts_1_3': True, 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=341%20U9340&class=&dpt_code=3410&ser_no=43630&semester=113-1&lang=CH', 'ts_1_4': True, 'course_id': 43630, 'instructor': '林建志'}\n",
      "  2. metadata: {'ts_1_8': True, 'time_slots': '1_8,1_9,5_1702', 'course_id': 62222, 'instructor': '黃銘傑', 'ts_5_1702': True, 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=A21%20M2490&class=&dpt_code=A410&ser_no=62222&semester=113-1&lang=CH', 'ts_1_9': True, 'title': '人工智慧、大數據與競爭法一'}\n",
      "  3. metadata: {'title': '人口統計學', 'course_id': 71504, 'instructor': '蘇士詠', 'time_slots': '3_6,3_7,3_8', 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=H41%20U0040&class=&dpt_code=H410&ser_no=71504&semester=113-1&lang=CH', 'ts_3_6': True, 'ts_3_7': True, 'ts_3_8': True}\n",
      "  4. metadata: {'course_id': 67518, 'time_slots': '', 'instructor': '溫在弘', 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=P46%20U0070&class=&dpt_code=P460&ser_no=67518&semester=113-1&lang=CH', 'title': '人口資料視覺化實作'}\n",
      "  5. metadata: {'title': '財務報表分析', 'course_id': 61032, 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=A21%20U6620&class=&dpt_code=A010&ser_no=61032&semester=113-1&lang=CH', 'time_slots': '1_8,1_9', 'instructor': '黃承祖', 'ts_1_9': True, 'ts_1_8': True}\n",
      "\n",
      "🔍 對 query '想選修跟 Python 資料分析有關的課程' 做相似度檢索，前 3 筆結果：\n",
      "  [1] 課程名稱：程式設計與資料分析, 時段：2_6,2_7,2_8\n",
      "  [2] 課程名稱：數據分析之計算統計學, 時段：1_6,4_6,4_7\n",
      "  [3] 課程名稱：資料選讀, 時段：2_A,2_B\n",
      "\n",
      "🔍 對 query '想選修跟 Python 資料分析有關的課程' 做相似度檢索，前 3 筆結果：\n",
      "  [1] 課程名稱：程式設計與資料分析, 時段：2_6,2_7,2_8\n",
      "  [2] 課程名稱：數據分析之計算統計學, 時段：1_6,4_6,4_7\n",
      "  [3] 課程名稱：資料選讀, 時段：2_A,2_B\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pydantic import SecretStr\n",
    "\n",
    "# 1. 設定 Chroma 資料夾路徑\n",
    "CHROMA_LOCAL_DIR = os.path.join(\"persist\", \"chroma_data\")\n",
    "\n",
    "# 2. 檢查目錄結構\n",
    "print(\"🔍 CHROMA_LOCAL_DIR 內容：\")\n",
    "for root, dirs, files in os.walk(CHROMA_LOCAL_DIR):\n",
    "    level = root.replace(CHROMA_LOCAL_DIR, \"\").count(os.sep)\n",
    "    indent = \"  \" * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    for f in files:\n",
    "        print(f\"{indent}  └─ {f}\")\n",
    "\n",
    "# 3. 初始化 embedding 函式（用同一套機制即可）\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"請先設定環境變數 OPENAI_API_KEY\")\n",
    "\n",
    "embedding = OpenAIEmbeddings(api_key=SecretStr(OPENAI_API_KEY))\n",
    "\n",
    "# 4. 嘗試讀取 Chroma 資料庫\n",
    "try:\n",
    "    vectordb = Chroma(persist_directory=CHROMA_LOCAL_DIR, embedding_function=embedding)\n",
    "    # 讀取所有文件列表（metadata + 內容），用來檢查是否載入成功\n",
    "    all_data = vectordb.get()\n",
    "    documents = all_data.get(\"documents\", [])\n",
    "    metadatas = all_data.get(\"metadatas\", [])\n",
    "\n",
    "    print(f\"\\n✅ 總共在 Chroma 找到 {len(documents)} 筆文件\")\n",
    "    # 印出前 5 筆 metadata 來檢查\n",
    "    for idx, meta in enumerate(metadatas[:5], start=1):\n",
    "        print(f\"  {idx}. metadata: {meta}\")\n",
    "\n",
    "    # 5. 若要進一步測試相似度檢索，可以呼叫 similarity_search：\n",
    "    sample_query = \"想選修跟 Python 資料分析有關的課程\"\n",
    "    hits = vectordb.similarity_search(sample_query, k=3)\n",
    "    print(f\"\\n🔍 對 query '{sample_query}' 做相似度檢索，前 3 筆結果：\")\n",
    "    for i, hit in enumerate(hits, start=1):\n",
    "        print(f\"  [{i}] 課程名稱：{hit.metadata.get('title')}, 時段：{hit.metadata.get('time_slots')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"❌ 讀取 Chroma 資料庫失敗：\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
