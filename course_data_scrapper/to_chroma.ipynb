{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696a39a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:18<00:00,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å®Œæˆï¼šç¸½å…±è™•ç† 1300 ç­†èª²ç¨‹ï¼Œçµæœå·²å„²å­˜æ–¼ persist/chroma_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "import tiktoken\n",
    "from pydantic import SecretStr\n",
    "from chromadb.config import Settings\n",
    "\n",
    "RateLimitError = Exception\n",
    "\n",
    "# ====== CONFIG ======\n",
    "SOURCE_JSON = \"parsed_course_data.json\"\n",
    "CHROMA_DIR = \"persist/chroma_data\"\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "MAX_TOKENS_PER_BATCH = 250000\n",
    "BATCH_DELAY_SECONDS = 1.5\n",
    "# =====================\n",
    "\n",
    "# âœ… åˆå§‹åŒ–\n",
    "# æ–¹æ³• 1ï¼šä½¿ç”¨ SecretStr è½‰æ›\n",
    "embedding_model = OpenAIEmbeddings(api_key=SecretStr(OPENAI_API_KEY))\n",
    "# æˆ–è€…æ–¹æ³• 2ï¼šä½¿ç”¨ç’°å¢ƒè®Šæ•¸ï¼ˆç„¡éœ€é¡å¤–è¨­ç½®ï¼‰\n",
    "# embedding_model = OpenAIEmbeddings()\n",
    "tokenizer = tiktoken.encoding_for_model(EMBEDDING_MODEL_NAME)\n",
    "\n",
    "# âœ… è¼‰å…¥èª²ç¨‹è³‡æ–™\n",
    "with open(SOURCE_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_courses = json.load(f)\n",
    "\n",
    "\n",
    "# âœ… æ™‚é–“æ¬„ä½è½‰ metadataï¼ˆå«å­—ä¸²èˆ‡å¸ƒæ—æ¨™è¨˜ï¼‰\n",
    "def build_time_metadata(time_slots):\n",
    "    if isinstance(time_slots, list):\n",
    "        time_str = \",\".join(time_slots)\n",
    "        time_flags = {f\"ts_{ts}\": True for ts in time_slots}\n",
    "    else:\n",
    "        time_str = \"\"\n",
    "        time_flags = {}\n",
    "    return {\"time_slots\": time_str, **time_flags}\n",
    "\n",
    "\n",
    "# âœ… å»ºç«‹ Document åˆ—è¡¨\n",
    "documents = []\n",
    "for c in raw_courses:\n",
    "    content = f\"èª²ç¨‹åç¨±ï¼š{c['title']}\\nèª²ç¨‹ä»‹ç´¹ï¼š{c['description']}\\næˆèª²è€å¸«ï¼š{c.get('instructor','')}\\nèª²ç¨‹ç¶²å€ï¼š{c.get('course_url','')}\"\n",
    "    metadata = {\"course_id\": c[\"course_id\"], \"title\": c[\"title\"], \"instructor\": c.get(\"instructor\", \"\"), \"course_url\": c.get(\"course_url\", \"\"), **build_time_metadata(c.get(\"time_slots\", []))}\n",
    "    documents.append(Document(page_content=content, metadata=metadata))\n",
    "\n",
    "\n",
    "# âœ… è¨ˆç®— token æ•¸\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "\n",
    "# âœ… æŒ‰ token æ•¸åˆ†æ‰¹\n",
    "def batch_by_token_limit(docs: List[Document], max_tokens: int):\n",
    "    batch, total = [], 0\n",
    "    for doc in docs:\n",
    "        tokens = count_tokens(doc.page_content)\n",
    "        if total + tokens > max_tokens and batch:\n",
    "            yield batch\n",
    "            batch, total = [], 0\n",
    "        batch.append(doc)\n",
    "        total += tokens\n",
    "    if batch:\n",
    "        yield batch\n",
    "\n",
    "\n",
    "# âœ… å®‰å…¨å°è£çš„ add_textsï¼Œå…§å»º retry\n",
    "@retry(wait=wait_random_exponential(min=2, max=10), stop=stop_after_attempt(5))\n",
    "def safe_add_texts(vectordb, texts, metadatas):\n",
    "    vectordb.add_texts(texts=texts, metadatas=metadatas)\n",
    "\n",
    "\n",
    "# âœ… åˆå§‹åŒ– Chroma å‘é‡åº«ï¼Œè¨­ç½® persist_directory\n",
    "vectordb = Chroma(persist_directory=CHROMA_DIR, embedding_function=embedding_model, client_settings=Settings(is_persistent=True))\n",
    "\n",
    "# âœ… åˆ†æ‰¹åµŒå…¥èˆ‡å¯«å…¥\n",
    "batches = list(batch_by_token_limit(documents, MAX_TOKENS_PER_BATCH))\n",
    "for i, batch in enumerate(tqdm(batches, desc=\"Embedding batches\")):\n",
    "    texts = [d.page_content for d in batch]\n",
    "    metadatas = [d.metadata for d in batch]\n",
    "    safe_add_texts(vectordb, texts, metadatas)\n",
    "    time.sleep(BATCH_DELAY_SECONDS)\n",
    "\n",
    "# è³‡æ–™æœƒè‡ªå‹•å„²å­˜ï¼Œä¸éœ€è¦å‘¼å« persist()\n",
    "print(f\"âœ… å®Œæˆï¼šç¸½å…±è™•ç† {len(documents)} ç­†èª²ç¨‹ï¼Œçµæœå·²å„²å­˜æ–¼ {CHROMA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd074a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²å£“ç¸®ç‚º chroma_data.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "\n",
    "def zip_chroma_data(folder_path, output_zip=\"chroma_data.zip\"):\n",
    "    with zipfile.ZipFile(output_zip, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                filepath = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(filepath, start=folder_path)\n",
    "                zipf.write(filepath, arcname)\n",
    "\n",
    "\n",
    "zip_chroma_data(\"persist/chroma_data\")  # â¬… é€™è£¡æ”¹æˆä½ çš„ Chroma è³‡æ–™å¤¾è·¯å¾‘\n",
    "print(\"âœ… å·²å£“ç¸®ç‚º chroma_data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3dc8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸé€£ç·šï¼Œåˆ—å‡º container ä¸­çš„ blob:\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "account_name = os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\")\n",
    "account_key = os.getenv(\"AZURE_STORAGE_ACCOUNT_KEY\")\n",
    "container_name = os.getenv(\"AZURE_BLOB_CONTAINER\")\n",
    "\n",
    "connection_str = f\"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_str)\n",
    "\n",
    "try:\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    print(\"âœ… æˆåŠŸé€£ç·šï¼Œåˆ—å‡º container ä¸­çš„ blob:\")\n",
    "    for blob in container_client.list_blobs():\n",
    "        print(\" -\", blob.name)\n",
    "except Exception as e:\n",
    "    print(\"âŒ é€£ç·šå¤±æ•—ï¼Œè«‹æª¢æŸ¥ account name/key/container name\")\n",
    "    print(\"éŒ¯èª¤è¨Šæ¯ï¼š\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6034fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¸¬è©¦æª”æ¡ˆå·²ä¸Šå‚³\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobClient\n",
    "from azure.storage.blob import ContentSettings\n",
    "\n",
    "test_blob_name = \"test-upload.txt\"\n",
    "test_blob_client = blob_service_client.get_blob_client(container=container_name, blob=test_blob_name)\n",
    "\n",
    "with open(\"test-upload.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"é€™æ˜¯ä¸€å€‹æ¸¬è©¦æª”æ¡ˆ\")\n",
    "\n",
    "with open(\"test-upload.txt\", \"rb\") as data:\n",
    "    test_blob_client.upload_blob(data, overwrite=True, content_settings=ContentSettings(content_type=\"text/plain\"))\n",
    "    print(\"âœ… æ¸¬è©¦æª”æ¡ˆå·²ä¸Šå‚³\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35f2e161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ“¤ Uploading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23.8M/23.8M [01:31<00:00, 261kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ä¸Šå‚³å®Œæˆï¼šcourse_vector.zip è‡³ container course-data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.storage.blob import BlobClient, ContentSettings\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --------------- ğŸ”§ è¨­å®šå¸¸æ•¸ ----------------\n",
    "LOCAL_FILE = \"chroma_data.zip\"\n",
    "BLOB_NAME = \"course_vector.zip\"\n",
    "CONTENT_TYPE = \"application/zip\"\n",
    "MAX_SINGLE_PUT_SIZE = 16 * 1024 * 1024  # 16MB\n",
    "MAX_BLOCK_SIZE = 4 * 1024 * 1024  # 4MB\n",
    "TIMEOUT = 600\n",
    "MAX_CONCURRENCY = 4\n",
    "\n",
    "# --------------- ğŸ” è¼‰å…¥æ†‘è­‰ ----------------\n",
    "load_dotenv()\n",
    "ACCOUNT_NAME = os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\")\n",
    "ACCOUNT_KEY = os.getenv(\"AZURE_STORAGE_ACCOUNT_KEY\")\n",
    "CONTAINER_NAME = os.getenv(\"AZURE_BLOB_CONTAINER\")\n",
    "\n",
    "if not all([ACCOUNT_NAME, ACCOUNT_KEY, CONTAINER_NAME]):\n",
    "    raise ValueError(\"âŒ è«‹ç¢ºèª .env ä¸­å¸³è™Ÿè³‡è¨Šæ˜¯å¦é½Šå…¨\")\n",
    "\n",
    "# --------------- ğŸ”— å»ºç«‹é€£ç·šå­—ä¸² ----------------\n",
    "AZURE_CONN_STR = f\"DefaultEndpointsProtocol=https;AccountName={ACCOUNT_NAME};AccountKey={ACCOUNT_KEY};EndpointSuffix=core.windows.net\"\n",
    "\n",
    "\n",
    "# --------------- ğŸ“¦ æº–å‚™ä¸Šå‚³æª”æ¡ˆ ----------------\n",
    "class TqdmUploadWrapper:\n",
    "    def __init__(self, file, total):\n",
    "        self.file = file\n",
    "        self.progress_bar = tqdm(total=total, unit=\"B\", unit_scale=True, desc=\"ğŸ“¤ Uploading\")\n",
    "\n",
    "    def read(self, size):\n",
    "        data = self.file.read(size)\n",
    "        self.progress_bar.update(len(data))\n",
    "        return data\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            chunk = self.read(1024 * 1024)  # Read in 1MB chunks\n",
    "            if not chunk:\n",
    "                break\n",
    "            yield chunk\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        return getattr(self.file, attr)\n",
    "\n",
    "\n",
    "# --------------- â˜ï¸ å»ºç«‹ BlobClient ä¸¦ä¸Šå‚³ ----------------\n",
    "file_size = os.path.getsize(LOCAL_FILE)\n",
    "\n",
    "blob_client = BlobClient.from_connection_string(conn_str=AZURE_CONN_STR, container_name=CONTAINER_NAME, blob_name=BLOB_NAME, max_single_put_size=MAX_SINGLE_PUT_SIZE, max_block_size=MAX_BLOCK_SIZE)\n",
    "\n",
    "with open(LOCAL_FILE, \"rb\") as f:\n",
    "    wrapped = TqdmUploadWrapper(f, total=file_size)\n",
    "    blob_client.upload_blob(data=wrapped, blob_type=\"BlockBlob\", overwrite=True, content_settings=ContentSettings(content_type=CONTENT_TYPE), max_concurrency=MAX_CONCURRENCY, timeout=TIMEOUT)\n",
    "    wrapped.progress_bar.close()\n",
    "\n",
    "print(f\"\\nâœ… ä¸Šå‚³å®Œæˆï¼š{BLOB_NAME} è‡³ container {CONTAINER_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93cd0c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” CHROMA_LOCAL_DIR å…§å®¹ï¼š\n",
      "chroma_data/\n",
      "  â””â”€ chroma.sqlite3\n",
      "  8f32e79c-8252-4231-8783-bf4c51b313b8/\n",
      "    â””â”€ data_level0.bin\n",
      "    â””â”€ header.bin\n",
      "    â””â”€ index_metadata.pickle\n",
      "    â””â”€ length.bin\n",
      "    â””â”€ link_lists.bin\n",
      "\n",
      "âœ… ç¸½å…±åœ¨ Chroma æ‰¾åˆ° 1300 ç­†æ–‡ä»¶\n",
      "  1. metadata: {'time_slots': '1_3,1_4', 'title': '(å¤§)æ³•å®˜å¦‚ä½•æ€è€ƒï¼Ÿå¸æ³•è¡Œç‚ºèˆ‡å¸æ³•æ”¿æ²»ä¸Š', 'ts_1_3': True, 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=341%20U9340&class=&dpt_code=3410&ser_no=43630&semester=113-1&lang=CH', 'ts_1_4': True, 'course_id': 43630, 'instructor': 'æ—å»ºå¿—'}\n",
      "  2. metadata: {'ts_1_8': True, 'time_slots': '1_8,1_9,5_1702', 'course_id': 62222, 'instructor': 'é»ƒéŠ˜å‚‘', 'ts_5_1702': True, 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=A21%20M2490&class=&dpt_code=A410&ser_no=62222&semester=113-1&lang=CH', 'ts_1_9': True, 'title': 'äººå·¥æ™ºæ…§ã€å¤§æ•¸æ“šèˆ‡ç«¶çˆ­æ³•ä¸€'}\n",
      "  3. metadata: {'title': 'äººå£çµ±è¨ˆå­¸', 'course_id': 71504, 'instructor': 'è˜‡å£«è© ', 'time_slots': '3_6,3_7,3_8', 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=H41%20U0040&class=&dpt_code=H410&ser_no=71504&semester=113-1&lang=CH', 'ts_3_6': True, 'ts_3_7': True, 'ts_3_8': True}\n",
      "  4. metadata: {'course_id': 67518, 'time_slots': '', 'instructor': 'æº«åœ¨å¼˜', 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=P46%20U0070&class=&dpt_code=P460&ser_no=67518&semester=113-1&lang=CH', 'title': 'äººå£è³‡æ–™è¦–è¦ºåŒ–å¯¦ä½œ'}\n",
      "  5. metadata: {'title': 'è²¡å‹™å ±è¡¨åˆ†æ', 'course_id': 61032, 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=A21%20U6620&class=&dpt_code=A010&ser_no=61032&semester=113-1&lang=CH', 'time_slots': '1_8,1_9', 'instructor': 'é»ƒæ‰¿ç¥–', 'ts_1_9': True, 'ts_1_8': True}\n",
      "\n",
      "âœ… ç¸½å…±åœ¨ Chroma æ‰¾åˆ° 1300 ç­†æ–‡ä»¶\n",
      "  1. metadata: {'time_slots': '1_3,1_4', 'title': '(å¤§)æ³•å®˜å¦‚ä½•æ€è€ƒï¼Ÿå¸æ³•è¡Œç‚ºèˆ‡å¸æ³•æ”¿æ²»ä¸Š', 'ts_1_3': True, 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=341%20U9340&class=&dpt_code=3410&ser_no=43630&semester=113-1&lang=CH', 'ts_1_4': True, 'course_id': 43630, 'instructor': 'æ—å»ºå¿—'}\n",
      "  2. metadata: {'ts_1_8': True, 'time_slots': '1_8,1_9,5_1702', 'course_id': 62222, 'instructor': 'é»ƒéŠ˜å‚‘', 'ts_5_1702': True, 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=A21%20M2490&class=&dpt_code=A410&ser_no=62222&semester=113-1&lang=CH', 'ts_1_9': True, 'title': 'äººå·¥æ™ºæ…§ã€å¤§æ•¸æ“šèˆ‡ç«¶çˆ­æ³•ä¸€'}\n",
      "  3. metadata: {'title': 'äººå£çµ±è¨ˆå­¸', 'course_id': 71504, 'instructor': 'è˜‡å£«è© ', 'time_slots': '3_6,3_7,3_8', 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=H41%20U0040&class=&dpt_code=H410&ser_no=71504&semester=113-1&lang=CH', 'ts_3_6': True, 'ts_3_7': True, 'ts_3_8': True}\n",
      "  4. metadata: {'course_id': 67518, 'time_slots': '', 'instructor': 'æº«åœ¨å¼˜', 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=P46%20U0070&class=&dpt_code=P460&ser_no=67518&semester=113-1&lang=CH', 'title': 'äººå£è³‡æ–™è¦–è¦ºåŒ–å¯¦ä½œ'}\n",
      "  5. metadata: {'title': 'è²¡å‹™å ±è¡¨åˆ†æ', 'course_id': 61032, 'course_url': 'https://nol.ntu.edu.tw/nol/coursesearch/print_table.php?course_id=A21%20U6620&class=&dpt_code=A010&ser_no=61032&semester=113-1&lang=CH', 'time_slots': '1_8,1_9', 'instructor': 'é»ƒæ‰¿ç¥–', 'ts_1_9': True, 'ts_1_8': True}\n",
      "\n",
      "ğŸ” å° query 'æƒ³é¸ä¿®è·Ÿ Python è³‡æ–™åˆ†ææœ‰é—œçš„èª²ç¨‹' åšç›¸ä¼¼åº¦æª¢ç´¢ï¼Œå‰ 3 ç­†çµæœï¼š\n",
      "  [1] èª²ç¨‹åç¨±ï¼šç¨‹å¼è¨­è¨ˆèˆ‡è³‡æ–™åˆ†æ, æ™‚æ®µï¼š2_6,2_7,2_8\n",
      "  [2] èª²ç¨‹åç¨±ï¼šæ•¸æ“šåˆ†æä¹‹è¨ˆç®—çµ±è¨ˆå­¸, æ™‚æ®µï¼š1_6,4_6,4_7\n",
      "  [3] èª²ç¨‹åç¨±ï¼šè³‡æ–™é¸è®€, æ™‚æ®µï¼š2_A,2_B\n",
      "\n",
      "ğŸ” å° query 'æƒ³é¸ä¿®è·Ÿ Python è³‡æ–™åˆ†ææœ‰é—œçš„èª²ç¨‹' åšç›¸ä¼¼åº¦æª¢ç´¢ï¼Œå‰ 3 ç­†çµæœï¼š\n",
      "  [1] èª²ç¨‹åç¨±ï¼šç¨‹å¼è¨­è¨ˆèˆ‡è³‡æ–™åˆ†æ, æ™‚æ®µï¼š2_6,2_7,2_8\n",
      "  [2] èª²ç¨‹åç¨±ï¼šæ•¸æ“šåˆ†æä¹‹è¨ˆç®—çµ±è¨ˆå­¸, æ™‚æ®µï¼š1_6,4_6,4_7\n",
      "  [3] èª²ç¨‹åç¨±ï¼šè³‡æ–™é¸è®€, æ™‚æ®µï¼š2_A,2_B\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pydantic import SecretStr\n",
    "\n",
    "# 1. è¨­å®š Chroma è³‡æ–™å¤¾è·¯å¾‘\n",
    "CHROMA_LOCAL_DIR = os.path.join(\"persist\", \"chroma_data\")\n",
    "\n",
    "# 2. æª¢æŸ¥ç›®éŒ„çµæ§‹\n",
    "print(\"ğŸ” CHROMA_LOCAL_DIR å…§å®¹ï¼š\")\n",
    "for root, dirs, files in os.walk(CHROMA_LOCAL_DIR):\n",
    "    level = root.replace(CHROMA_LOCAL_DIR, \"\").count(os.sep)\n",
    "    indent = \"  \" * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    for f in files:\n",
    "        print(f\"{indent}  â””â”€ {f}\")\n",
    "\n",
    "# 3. åˆå§‹åŒ– embedding å‡½å¼ï¼ˆç”¨åŒä¸€å¥—æ©Ÿåˆ¶å³å¯ï¼‰\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"è«‹å…ˆè¨­å®šç’°å¢ƒè®Šæ•¸ OPENAI_API_KEY\")\n",
    "\n",
    "embedding = OpenAIEmbeddings(api_key=SecretStr(OPENAI_API_KEY))\n",
    "\n",
    "# 4. å˜—è©¦è®€å– Chroma è³‡æ–™åº«\n",
    "try:\n",
    "    vectordb = Chroma(persist_directory=CHROMA_LOCAL_DIR, embedding_function=embedding)\n",
    "    # è®€å–æ‰€æœ‰æ–‡ä»¶åˆ—è¡¨ï¼ˆmetadata + å…§å®¹ï¼‰ï¼Œç”¨ä¾†æª¢æŸ¥æ˜¯å¦è¼‰å…¥æˆåŠŸ\n",
    "    all_data = vectordb.get()\n",
    "    documents = all_data.get(\"documents\", [])\n",
    "    metadatas = all_data.get(\"metadatas\", [])\n",
    "\n",
    "    print(f\"\\nâœ… ç¸½å…±åœ¨ Chroma æ‰¾åˆ° {len(documents)} ç­†æ–‡ä»¶\")\n",
    "    # å°å‡ºå‰ 5 ç­† metadata ä¾†æª¢æŸ¥\n",
    "    for idx, meta in enumerate(metadatas[:5], start=1):\n",
    "        print(f\"  {idx}. metadata: {meta}\")\n",
    "\n",
    "    # 5. è‹¥è¦é€²ä¸€æ­¥æ¸¬è©¦ç›¸ä¼¼åº¦æª¢ç´¢ï¼Œå¯ä»¥å‘¼å« similarity_searchï¼š\n",
    "    sample_query = \"æƒ³é¸ä¿®è·Ÿ Python è³‡æ–™åˆ†ææœ‰é—œçš„èª²ç¨‹\"\n",
    "    hits = vectordb.similarity_search(sample_query, k=3)\n",
    "    print(f\"\\nğŸ” å° query '{sample_query}' åšç›¸ä¼¼åº¦æª¢ç´¢ï¼Œå‰ 3 ç­†çµæœï¼š\")\n",
    "    for i, hit in enumerate(hits, start=1):\n",
    "        print(f\"  [{i}] èª²ç¨‹åç¨±ï¼š{hit.metadata.get('title')}, æ™‚æ®µï¼š{hit.metadata.get('time_slots')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"âŒ è®€å– Chroma è³‡æ–™åº«å¤±æ•—ï¼š\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
