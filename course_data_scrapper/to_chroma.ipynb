{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a39a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_30396\\3932452636.py:78: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(persist_directory=CHROMA_DIR, embedding_function=embedding_model)\n",
      "Embedding batches: 100%|██████████| 8/8 [01:55<00:00, 14.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 完成：總共處理 1300 筆課程，結果已儲存於 ../persist/chroma_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_30396\\3932452636.py:88: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "import tiktoken\n",
    "\n",
    "RateLimitError = Exception\n",
    "\n",
    "# ====== CONFIG ======\n",
    "SOURCE_JSON = \"parsed_course_data.json\"\n",
    "CHROMA_DIR = \"persist/chroma_data\"\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "MAX_TOKENS_PER_BATCH = 250000\n",
    "BATCH_DELAY_SECONDS = 1.5\n",
    "# =====================\n",
    "\n",
    "# ✅ 初始化\n",
    "embedding_model = OpenAIEmbeddings(api_key=OPENAI_API_KEY)\n",
    "tokenizer = tiktoken.encoding_for_model(EMBEDDING_MODEL_NAME)\n",
    "\n",
    "# ✅ 載入課程資料\n",
    "with open(SOURCE_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_courses = json.load(f)\n",
    "\n",
    "\n",
    "# ✅ 時間欄位轉 metadata（含字串與布林標記）\n",
    "def build_time_metadata(time_slots):\n",
    "    if isinstance(time_slots, list):\n",
    "        time_str = \",\".join(time_slots)\n",
    "        time_flags = {f\"ts_{ts}\": True for ts in time_slots}\n",
    "    else:\n",
    "        time_str = \"\"\n",
    "        time_flags = {}\n",
    "    return {\"time_slots\": time_str, **time_flags}\n",
    "\n",
    "\n",
    "# ✅ 建立 Document 列表\n",
    "documents = []\n",
    "for c in raw_courses:\n",
    "    content = f\"課程名稱：{c['title']}\\n課程介紹：{c['description']}\\n授課老師：{c.get('instructor','')}\\n課程網址：{c.get('course_url','')}\"\n",
    "    metadata = {\"course_id\": c[\"course_id\"], \"title\": c[\"title\"], \"instructor\": c.get(\"instructor\", \"\"), \"course_url\": c.get(\"course_url\", \"\"), **build_time_metadata(c.get(\"time_slots\", []))}\n",
    "    documents.append(Document(page_content=content, metadata=metadata))\n",
    "\n",
    "\n",
    "# ✅ 計算 token 數\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "\n",
    "# ✅ 按 token 數分批\n",
    "def batch_by_token_limit(docs: List[Document], max_tokens: int):\n",
    "    batch, total = [], 0\n",
    "    for doc in docs:\n",
    "        tokens = count_tokens(doc.page_content)\n",
    "        if total + tokens > max_tokens and batch:\n",
    "            yield batch\n",
    "            batch, total = [], 0\n",
    "        batch.append(doc)\n",
    "        total += tokens\n",
    "    if batch:\n",
    "        yield batch\n",
    "\n",
    "\n",
    "# ✅ 安全封裝的 add_texts，內建 retry\n",
    "@retry(wait=wait_random_exponential(min=2, max=10), stop=stop_after_attempt(5))\n",
    "def safe_add_texts(vectordb, texts, metadatas):\n",
    "    vectordb.add_texts(texts=texts, metadatas=metadatas)\n",
    "\n",
    "\n",
    "# ✅ 初始化 Chroma 向量庫\n",
    "vectordb = Chroma(persist_directory=CHROMA_DIR, embedding_function=embedding_model)\n",
    "\n",
    "# ✅ 分批嵌入與寫入\n",
    "batches = list(batch_by_token_limit(documents, MAX_TOKENS_PER_BATCH))\n",
    "for i, batch in enumerate(tqdm(batches, desc=\"Embedding batches\")):\n",
    "    texts = [d.page_content for d in batch]\n",
    "    metadatas = [d.metadata for d in batch]\n",
    "    safe_add_texts(vectordb, texts, metadatas)\n",
    "    time.sleep(BATCH_DELAY_SECONDS)\n",
    "\n",
    "vectordb.persist()\n",
    "print(f\"✅ 完成：總共處理 {len(documents)} 筆課程，結果已儲存於 {CHROMA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd074a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 已壓縮為 chroma_data.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "\n",
    "def zip_chroma_data(folder_path, output_zip=\"chroma_data.zip\"):\n",
    "    with zipfile.ZipFile(output_zip, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                filepath = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(filepath, start=folder_path)\n",
    "                zipf.write(filepath, arcname)\n",
    "\n",
    "\n",
    "zip_chroma_data(\"persist/chroma_data\")  # ⬅ 這裡改成你的 Chroma 資料夾路徑\n",
    "print(\"✅ 已壓縮為 chroma_data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e3dc8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 成功連線，列出 container 中的 blob:\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "account_name = os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\")\n",
    "account_key = os.getenv(\"AZURE_STORAGE_ACCOUNT_KEY\")\n",
    "container_name = os.getenv(\"AZURE_BLOB_CONTAINER\")\n",
    "\n",
    "connection_str = f\"DefaultEndpointsProtocol=https;AccountName={account_name};AccountKey={account_key};EndpointSuffix=core.windows.net\"\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_str)\n",
    "\n",
    "try:\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    print(\"✅ 成功連線，列出 container 中的 blob:\")\n",
    "    for blob in container_client.list_blobs():\n",
    "        print(\" -\", blob.name)\n",
    "except Exception as e:\n",
    "    print(\"❌ 連線失敗，請檢查 account name/key/container name\")\n",
    "    print(\"錯誤訊息：\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6034fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 測試檔案已上傳\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobClient\n",
    "from azure.storage.blob import ContentSettings\n",
    "\n",
    "test_blob_name = \"test-upload.txt\"\n",
    "test_blob_client = blob_service_client.get_blob_client(container=container_name, blob=test_blob_name)\n",
    "\n",
    "with open(\"test-upload.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"這是一個測試檔案\")\n",
    "\n",
    "with open(\"test-upload.txt\", \"rb\") as data:\n",
    "    test_blob_client.upload_blob(data, overwrite=True, content_settings=ContentSettings(content_type=\"text/plain\"))\n",
    "    print(\"✅ 測試檔案已上傳\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35f2e161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "📤 Uploading: 100%|██████████| 23.8M/23.8M [01:03<00:00, 378kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 上傳完成：course_vector.zip 至 container course-data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.storage.blob import BlobClient, ContentSettings\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --------------- 🔧 設定常數 ----------------\n",
    "LOCAL_FILE = \"chroma_data.zip\"\n",
    "BLOB_NAME = \"course_vector.zip\"\n",
    "CONTENT_TYPE = \"application/zip\"\n",
    "MAX_SINGLE_PUT_SIZE = 16 * 1024 * 1024  # 16MB\n",
    "MAX_BLOCK_SIZE = 4 * 1024 * 1024  # 4MB\n",
    "TIMEOUT = 600\n",
    "MAX_CONCURRENCY = 4\n",
    "\n",
    "# --------------- 🔐 載入憑證 ----------------\n",
    "load_dotenv()\n",
    "ACCOUNT_NAME = os.getenv(\"AZURE_STORAGE_ACCOUNT_NAME\")\n",
    "ACCOUNT_KEY = os.getenv(\"AZURE_STORAGE_ACCOUNT_KEY\")\n",
    "CONTAINER_NAME = os.getenv(\"AZURE_BLOB_CONTAINER\")\n",
    "\n",
    "if not all([ACCOUNT_NAME, ACCOUNT_KEY, CONTAINER_NAME]):\n",
    "    raise ValueError(\"❌ 請確認 .env 中帳號資訊是否齊全\")\n",
    "\n",
    "# --------------- 🔗 建立連線字串 ----------------\n",
    "AZURE_CONN_STR = f\"DefaultEndpointsProtocol=https;AccountName={ACCOUNT_NAME};AccountKey={ACCOUNT_KEY};EndpointSuffix=core.windows.net\"\n",
    "\n",
    "\n",
    "# --------------- 📦 準備上傳檔案 ----------------\n",
    "class TqdmUploadWrapper:\n",
    "    def __init__(self, file, total):\n",
    "        self.file = file\n",
    "        self.progress_bar = tqdm(total=total, unit=\"B\", unit_scale=True, desc=\"📤 Uploading\")\n",
    "\n",
    "    def read(self, size):\n",
    "        data = self.file.read(size)\n",
    "        self.progress_bar.update(len(data))\n",
    "        return data\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        return getattr(self.file, attr)\n",
    "\n",
    "\n",
    "# --------------- ☁️ 建立 BlobClient 並上傳 ----------------\n",
    "file_size = os.path.getsize(LOCAL_FILE)\n",
    "\n",
    "blob_client = BlobClient.from_connection_string(conn_str=AZURE_CONN_STR, container_name=CONTAINER_NAME, blob_name=BLOB_NAME, max_single_put_size=MAX_SINGLE_PUT_SIZE, max_block_size=MAX_BLOCK_SIZE)\n",
    "\n",
    "with open(LOCAL_FILE, \"rb\") as f:\n",
    "    wrapped = TqdmUploadWrapper(f, total=file_size)\n",
    "    blob_client.upload_blob(data=wrapped, blob_type=\"BlockBlob\", overwrite=True, content_settings=ContentSettings(content_type=CONTENT_TYPE), max_concurrency=MAX_CONCURRENCY, timeout=TIMEOUT)\n",
    "    wrapped.progress_bar.close()\n",
    "\n",
    "print(f\"\\n✅ 上傳完成：{BLOB_NAME} 至 container {CONTAINER_NAME}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
